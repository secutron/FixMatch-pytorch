{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A.1.im.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQ4eaF0lXvovw8SHrhjOtb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/FixMatch-pytorch/blob/master/A_1_im.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na4WYXxkfI4C"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdhoeHGgsimM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8011cbce-31e4-4386-eadc-2851f1a6e14a"
      },
      "source": [
        "import os\n",
        "\n",
        "gpu_gtg = False\n",
        "if int(os.environ.get(\"COLAB_GPU\")) > 0:\n",
        "    gpu_gtg = \"COLAB_GPU\" in os.environ\n",
        "\n",
        "tpu_gtg = \"COLAB_TPU_ADDR\" in os.environ\n",
        "\n",
        "if tpu_gtg: # tpu\n",
        "    print(\"TPU\")\n",
        "    #VERSION = \"nightly\"\n",
        "\n",
        "    # https://github.com/pytorch/builder/pull/750\n",
        "    VERSION = \"20210304\" # was 20200607\" \n",
        "\n",
        "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "    !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5116  100  5116    0     0  73085      0 --:--:-- --:--:-- --:--:-- 73085\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20210304 ...\n",
            "Found existing installation: torch 1.9.0+cu102\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.26.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.15.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.34.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.53.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (21.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Uninstalling torch-1.9.0+cu102:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27ND-qg2tJEU"
      },
      "source": [
        "!pip install --pre pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYoQTy8JtJBU"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "import ignite\n",
        "import ignite.distributed as idist\n",
        "from ignite.engine import Engine, Events, create_supervised_evaluator, create_supervised_trainer\n",
        "from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\n",
        "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
        "from ignite.utils import setup_logger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va-GVsDLyijz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SMALL_SIZE = 8\n",
        "MEDIUM_SIZE = 12\n",
        "BIGGER_SIZE = 18\n",
        "\n",
        "plt.rc('font', size=SMALL_SIZE) # controls default text sizes\n",
        "plt.rc('xtick', labelsize=SMALL_SIZE) # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=SMALL_SIZE) # fontsize of the tick labels\n",
        "\n",
        "def training(local_rank, config, **kwargs):\n",
        "    print(\"local rank: \", local_rank)\n",
        "\n",
        "    ###########################################################\n",
        "    # 데이터 준비\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Pad(4),\n",
        "            transforms.RandomCrop(32, fill=128),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    #test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),])\n",
        "    test_transform = transforms.Compose([transforms.ToTensor(),])\n",
        "\n",
        "    if idist.get_local_rank() > 0:\n",
        "        idist.barrier()\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root=config[\"data_path\"], train=True, download=True, transform=train_transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root=config[\"data_path\"], train=False, download=True, transform=test_transform)\n",
        "\n",
        "    if idist.get_local_rank() == 0:\n",
        "        idist.barrier()\n",
        "\n",
        "    trainloader = idist.auto_dataloader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=config[\"num_workers\"], drop_last=True)\n",
        "    testloader = idist.auto_dataloader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=config[\"num_workers\"],)\n",
        "\n",
        "\n",
        "    images, labels = next(iter(trainloader))\n",
        "    # 64개\n",
        "    h = 8\n",
        "    w = 8\n",
        "\n",
        "    fig, ax = plt.subplots(h, w, figsize=(3 * w, 3 * h))\n",
        "    for n1 in range(h):\n",
        "        for n2 in range(w):\n",
        "            n12 = n1*w + n2\n",
        "            ax[n1, n2].imshow(np.transpose(images[n12].cpu().numpy(), (1, 2, 0)).astype('uint8'))\n",
        "            ax[n1, n2].set_title(np.round(labels[n12].cpu().numpy(), 1))\n",
        "    plt.savefig(f\"/content/batch_64_{idist.get_local_rank()}.png\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ###########################################################\n",
        "    # 모델, 옵티마이저, 로스, 트레이너, 이밸류에이터\n",
        "    num_classes = 10\n",
        "    model = models.resnet18(num_classes = num_classes)\n",
        "       \n",
        "    model = idist.auto_model(model)\n",
        "    optimizer = idist.auto_optim(optim.Adam(model.parameters(), lr=0.001))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(idist.device())\n",
        "\n",
        "    trainer = create_supervised_trainer(model, optimizer, criterion, device=idist.device())\n",
        "    trainer.logger = setup_logger(\"hkim-trainer\")\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy':Accuracy(),\n",
        "        'ce':Loss(criterion),\n",
        "    }\n",
        "\n",
        "    val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=idist.device())\n",
        "    val_evaluator.logger = setup_logger(\"hkim-val_evaluator\")\n",
        "\n",
        "    # track a running average of the scalar loss output for each batch.\n",
        "    RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n",
        "\n",
        "    ###########################################################\n",
        "    # 이벤트\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_validation_results(trainer):\n",
        "        state = val_evaluator.run(testloader)\n",
        "        metrics = val_evaluator.state.metrics\n",
        "        accuracy = metrics['accuracy']*100\n",
        "        loss = metrics['ce']\n",
        "        log_metrics(val_evaluator.logger, state.epoch, state.times[\"COMPLETED\"], \"validation evaluator\", state.metrics)\n",
        "\n",
        "    trainer.run(trainloader, max_epochs=config[\"num_epochs\"])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXJzm8yqtI-k"
      },
      "source": [
        "config = {\n",
        "    \"seed\": 543,\n",
        "    \"data_path\" : \"./cifar10\",\n",
        "    \"output_path\" : \"./output-cifar10/\",\n",
        "    \"model\" : \"resnet18\",\n",
        "    \"batch_size\" : 512,\n",
        "    \"momentum\" : 0.9,\n",
        "    \"weight_decay\" : 1e-4,\n",
        "    \"num_workers\" : 2,\n",
        "    \"num_epochs\" : 5,\n",
        "    \"learning_rate\" : 0.4,\n",
        "    \"num_warmup_epochs\" : 4,\n",
        "    \"validate_every\" : 3, \n",
        "    \"checkpoint_every\" : 1000,\n",
        "    \"backend\" : None, \n",
        "    \"resume_from\" : None, \n",
        "    \"log_every_iters\" : 15,\n",
        "    \"nproc_per_node\" : None, \n",
        "    \"stop_iteration\" : None, \n",
        "    \"with_amp\" : False,\n",
        "    \"log_interval\" : 10,\n",
        "    \"verbose_set\" : False,\n",
        "    \"verbose_set2\" : False,\n",
        "    \"verbose_loader\" : False\n",
        "\n",
        "}\n",
        "\n",
        "if not (tpu_gtg or gpu_gtg): # cpu\n",
        "    config[\"backend\"] = 'gloo'\n",
        "    config[\"nproc_per_node\"] = 8\n",
        "elif gpu_gtg: # gpu\n",
        "    config[\"backend\"] = 'nccl'\n",
        "    config[\"nproc_per_node\"] = 1\n",
        "elif tpu_gtg: # tpu\n",
        "    config[\"backend\"] = 'xla-tpu'\n",
        "    config[\"nproc_per_node\"] = 8\n",
        "else: # error\n",
        "    raise RuntimeError(\"Unknown environment: tpu_gtg {}, gpu_gtg {}\".format(tpu_gtg, gpu_gtg))\n",
        "\n",
        "if config[\"backend\"] == \"xla-tpu\" and config[\"with_amp\"]:\n",
        "    raise RuntimeError(\"The value of with_amp should be False if backend is xla\")\n",
        "\n",
        "\n",
        "dist_configs = {'nproc_per_node': config[\"nproc_per_node\"], \"start_method\": \"fork\"}  \n",
        "\n",
        "def log_metrics(logger, epoch, elapsed, tag, metrics):\n",
        "    metrics_output = \"\\n\".join([f\"\\t{k}: {v}\" for k, v in metrics.items()])\n",
        "    logger.info(f\"\\nEpoch {epoch} - Evaluation time (seconds): {elapsed:.2f} - {tag} metrics:\\n {metrics_output}\")\n",
        "\n",
        "with idist.Parallel(backend=config[\"backend\"], **dist_configs) as parallel:\n",
        "    parallel.run(training, config, a=1, b=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrhKjYC4mLaU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQL39wXmXx9k"
      },
      "source": [
        "## License\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXio6q3iX5Ig"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "Note: This is not an official [LG AI Research](https://www.lgresearch.ai/) product but sample code provided for an educational purpose\n",
        "\n",
        "<br/>\n",
        "author: John H. Kim\n",
        "<br/>  \n",
        "email: john.kim@lgresearch.ai / secutron@naver.com  \n",
        "\n",
        "\n",
        "---"
      ]
    }
  ]
}