{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ds_ViT_001.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTuaH9mnKOD5q82xQ4cIyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ffcb8ebd69d4477d9a10cf197756a675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd08a66f822f4e498e216da7501c97fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e81c90c08fdf4470bebab95064ee7df8",
              "IPY_MODEL_85c8efd45f0d45af8405c052daebc2d5",
              "IPY_MODEL_474fb84acb7047f9a281f56af60b047b"
            ]
          }
        },
        "dd08a66f822f4e498e216da7501c97fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e81c90c08fdf4470bebab95064ee7df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b6bc5064c61471bbc9577c8a0284baa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8228b0bf58614cafa148059b48d81586"
          }
        },
        "85c8efd45f0d45af8405c052daebc2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ec282f8d33540779e44c37bf1e3c6f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8f9085d92c24ad5903e36d3dac3cf86"
          }
        },
        "474fb84acb7047f9a281f56af60b047b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3547eed2097c49abb86cfbddb2b3f587",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 61418884.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f15a434ae9ce468787e7654a18125239"
          }
        },
        "8b6bc5064c61471bbc9577c8a0284baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8228b0bf58614cafa148059b48d81586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ec282f8d33540779e44c37bf1e3c6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8f9085d92c24ad5903e36d3dac3cf86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3547eed2097c49abb86cfbddb2b3f587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f15a434ae9ce468787e7654a18125239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/FixMatch-pytorch/blob/master/ds_ViT_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGo6d_MrkYE8",
        "outputId": "ce757a6a-7333-41b8-9deb-734276c4bb87"
      },
      "source": [
        "# 15SEP21 HKim\n",
        "# Exception: Installed CUDA version 11.0 does not match the version torch was compiled with 10.2, unable to compile cuda/cpp extensions without a matching cuda version.\n",
        "!pip install torch==1.7.1+cu110  -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n",
            "\u001b[K     |███████████████████████         | 834.1 MB 1.7 MB/s eta 0:03:13tcmalloc: large alloc 1147494400 bytes == 0x55f9cd1dc000 @  0x7fd20155f615 0x55f993ceb02c 0x55f993dcb17a 0x55f993cede4d 0x55f993ddfc0d 0x55f993d620d8 0x55f993d5cc35 0x55f993cef73a 0x55f993d61f40 0x55f993d5cc35 0x55f993cef73a 0x55f993d5e93b 0x55f993de0a56 0x55f993d5dfb3 0x55f993de0a56 0x55f993d5dfb3 0x55f993de0a56 0x55f993d5dfb3 0x55f993cefb99 0x55f993d32e79 0x55f993cee7b2 0x55f993d61e65 0x55f993d5cc35 0x55f993cef73a 0x55f993d5e93b 0x55f993d5cc35 0x55f993cef73a 0x55f993d5db0e 0x55f993cef65a 0x55f993d5dd67 0x55f993d5cc35\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7 MB 1.2 MB/s eta 0:01:22tcmalloc: large alloc 1434370048 bytes == 0x55fa11832000 @  0x7fd20155f615 0x55f993ceb02c 0x55f993dcb17a 0x55f993cede4d 0x55f993ddfc0d 0x55f993d620d8 0x55f993d5cc35 0x55f993cef73a 0x55f993d61f40 0x55f993d5cc35 0x55f993cef73a 0x55f993d5e93b 0x55f993de0a56 0x55f993d5dfb3 0x55f993de0a56 0x55f993d5dfb3 0x55f993de0a56 0x55f993d5dfb3 0x55f993cefb99 0x55f993d32e79 0x55f993cee7b2 0x55f993d61e65 0x55f993d5cc35 0x55f993cef73a 0x55f993d5e93b 0x55f993d5cc35 0x55f993cef73a 0x55f993d5db0e 0x55f993cef65a 0x55f993d5dd67 0x55f993d5cc35\n",
            "\u001b[K     |████████████████████████████████| 1156.7 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55fa6701e000 @  0x7fd20155f615 0x55f993ceb02c 0x55f993dcb17a 0x55f993cede4d 0x55f993ddfc0d 0x55f993d620d8 0x55f993d5cc35 0x55f993cef73a 0x55f993d5dd67 0x55f993d5cc35 0x55f993cef73a 0x55f993d5dd67 0x55f993d5cc35 0x55f993cef73a 0x55f993d5dd67 0x55f993d5cc35 0x55f993cef73a 0x55f993d5dd67 0x55f993d5cc35 0x55f993cef73a 0x55f993d5dd67 0x55f993cef65a 0x55f993d5dd67 0x55f993d5cc35 0x55f993cef73a 0x55f993d5e93b 0x55f993d5cc35 0x55f993cef73a 0x55f993d5e93b 0x55f993d5cc35 0x55f993cefdd1\n",
            "\u001b[K     |████████████████████████████████| 1156.8 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.7.1+cu110 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.7.1+cu110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7PiWd7XRhFI",
        "outputId": "70c854c1-464a-4317-aff8-28e3df9a57e1"
      },
      "source": [
        "# !pip install fairscale\n",
        "!pip install deepspeed\n",
        "!pip install einops"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deepspeed) (21.0)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.7.1+cu110)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.19.5)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.0.0)\n",
            "Requirement already satisfied: tensorboardX==1.8 in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.8)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed) (5.4.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed) (4.62.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.10.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->deepspeed) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deepspeed) (2.4.7)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cosph5pmEgh",
        "outputId": "528bde62-23df-40fc-d5a0-f8b5b03a2a11"
      },
      "source": [
        "!ds_report"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "DeepSpeed C++/CUDA extension op report\n",
            "--------------------------------------------------\n",
            "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
            "      runtime if needed. Op compatibility means that your system\n",
            "      meet the required dependencies to JIT install the op.\n",
            "--------------------------------------------------\n",
            "JIT compiled ops requires ninja\n",
            "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "op name ................ installed .. compatible\n",
            "--------------------------------------------------\n",
            "cpu_adam ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "fused_adam ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "fused_lamb ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "sparse_attn ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "transformer ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "stochastic_transformer . \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "async_io ............... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "transformer_inference .. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "utils .................. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "quantizer .............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "DeepSpeed general environment info:\n",
            "torch install path ............... ['/usr/local/lib/python3.7/dist-packages/torch']\n",
            "torch version .................... 1.7.1+cu110\n",
            "torch cuda version ............... 11.0\n",
            "nvcc version ..................... 11.0\n",
            "deepspeed install path ........... ['/usr/local/lib/python3.7/dist-packages/deepspeed']\n",
            "deepspeed info ................... 0.5.2, unknown, unknown\n",
            "deepspeed wheel compiled w. ...... torch 1.7, cuda 11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C40TM3QpXkp2",
        "outputId": "3a3da8cd-0aad-4977-cd2f-93b117d81a89"
      },
      "source": [
        "%%writefile ds_config.json\n",
        "\n",
        " {\n",
        "   \"train_batch_size\": 4,\n",
        "   \"steps_per_print\": 2000,\n",
        "   \"optimizer\": {\n",
        "     \"type\": \"Adam\",\n",
        "     \"params\": {\n",
        "       \"lr\": 0.001,\n",
        "       \"betas\": [\n",
        "         0.8,\n",
        "         0.999\n",
        "       ],\n",
        "       \"eps\": 1e-8,\n",
        "       \"weight_decay\": 3e-7\n",
        "     }\n",
        "   },\n",
        "   \"scheduler\": {\n",
        "     \"type\": \"WarmupLR\",\n",
        "     \"params\": {\n",
        "       \"warmup_min_lr\": 0,\n",
        "       \"warmup_max_lr\": 0.001,\n",
        "       \"warmup_num_steps\": 1000\n",
        "     }\n",
        "   },\n",
        "   \"wall_clock_breakdown\": false\n",
        " }\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ds_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXhf4Sy3Xknc",
        "outputId": "cd474bff-a7bc-4d77-d501-7fcb16ed23b3"
      },
      "source": [
        "%%writefile train_cifar10.py\n",
        "\n",
        "import argparse\n",
        "import deepspeed\n",
        "import torch\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import CIFAR10\n",
        "from time import perf_counter\n",
        "\n",
        "def add_argument():\n",
        "    \"\"\"\n",
        "    https://www.deepspeed.ai/tutorials/cifar-10/\n",
        "    \"\"\"\n",
        "    parser=argparse.ArgumentParser(description='CIFAR')\n",
        "\n",
        "    # data\n",
        "    # cuda\n",
        "    parser.add_argument('--with_cuda', default=False, action='store_true',\n",
        "                        help='use CPU in case there\\'s no GPU support')\n",
        "    parser.add_argument('--use_ema', default=False, action='store_true',\n",
        "                        help='whether use exponential moving average')\n",
        "\n",
        "    # train\n",
        "    parser.add_argument('-b', '--batch_size', default=512, type=int,\n",
        "                        help='mini-batch size (default: 32)')\n",
        "    parser.add_argument('-e', '--epochs', default=30, type=int,\n",
        "                        help='number of total epochs (default: 30)')\n",
        "    parser.add_argument('--local_rank', type=int, default=-1,\n",
        "                    help='local rank passed from distributed launcher')\n",
        "\n",
        "    # Include DeepSpeed configuration arguments\n",
        "    parser = deepspeed.add_config_arguments(parser)\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\"\"\"\n",
        "https://yhkim4504.tistory.com/5\n",
        "https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit_pytorch.py\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange, repeat\n",
        "from torch import nn\n",
        "\n",
        "MIN_NUM_PATCHES = 16\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head *  heads\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask = None):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
        "\n",
        "        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
        "        mask_value = -torch.finfo(dots.dtype).max\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\n",
        "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n",
        "            mask = mask[:, None, :] * mask[:, :, None]\n",
        "            dots.masked_fill_(~mask, mask_value)\n",
        "            del mask\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = torch.einsum('bhij,bhjd->bhid', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out =  self.to_out(out)\n",
        "        return out\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                Residual(PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout))),\n",
        "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout)))\n",
        "            ]))\n",
        "    def forward(self, x, mask = None):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x, mask = mask)\n",
        "            x = ff(x)\n",
        "        return x\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
        "        super().__init__()\n",
        "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        patch_dim = channels * patch_size ** 2\n",
        "        assert num_patches > MIN_NUM_PATCHES, f'your number of patches ({num_patches}) is way too small for attention to be effective (at least 16). Try decreasing your patch size'\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
        "\n",
        "        self.pool = pool\n",
        "        self.to_latent = nn.Identity()\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img, mask = None):\n",
        "        p = self.patch_size\n",
        "\n",
        "        x = rearrange(img, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = p, p2 = p)\n",
        "        x = self.patch_to_embedding(x)\n",
        "        b, n, _ = x.shape\n",
        "\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.transformer(x, mask)\n",
        "\n",
        "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
        "\n",
        "        x = self.to_latent(x)\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "def main():\n",
        "    args = add_argument()\n",
        "    dataset = CIFAR10('.', download=True, transform=ToTensor())\n",
        "    trainloader = torch.utils.data.DataLoader(dataset,\n",
        "                                batch_size=args.batch_size,\n",
        "                                shuffle=True,\n",
        "                                num_workers=8)\n",
        "    huge_model = ViT(\n",
        "        image_size=32,\n",
        "        patch_size=4,\n",
        "        num_classes=10,\n",
        "        dim=512,\n",
        "        depth=8,\n",
        "        heads=8,\n",
        "        mlp_dim=2048,\n",
        "        dropout=0.1,\n",
        "        emb_dropout=0.1\n",
        "    )\n",
        "    lr = 0.001\n",
        "    warmup_steps = 1000\n",
        "    remain_steps = (args.epochs * len(trainloader) - warmup_steps)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        huge_model.parameters(),\n",
        "        lr=lr,\n",
        "        betas=(0.8, 0.999),\n",
        "        eps=1e-8,\n",
        "        weight_decay=3e-7)\n",
        "    torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer,\n",
        "        lambda epoch: (epoch + 1) / warmup_steps * lr if epoch < warmup_steps else (epoch - warmup_steps) * lr / remain_steps)\n",
        "    model_engine, _, trainloader_ds, _ = deepspeed.initialize(\n",
        "        args=args,\n",
        "        model=huge_model,\n",
        "        model_parameters=huge_model.parameters(),\n",
        "        training_data=dataset)\n",
        "\n",
        "    # training w/ DeepSpeed\n",
        "    start_time = perf_counter()\n",
        "    for data in trainloader_ds:\n",
        "            inputs = data[0].to(model_engine.device)\n",
        "            labels = data[1].to(model_engine.device)\n",
        "\n",
        "            outputs = model_engine(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            model_engine.backward(loss)\n",
        "            model_engine.step()\n",
        "    ds_time = (perf_counter() - start_time) / 60\n",
        "    print('###################################################################')\n",
        "    print(f'Training CIFAR10 using DeepSpeed used {ds_time:.3f} minutes')\n",
        "\n",
        "    # regular training\n",
        "    model = huge_model.to(device)\n",
        "    start_time = perf_counter()\n",
        "    for data in trainloader:\n",
        "        inputs = data[0].to(device)\n",
        "        labels = data[1].to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    no_ds_time = (perf_counter() - start_time) / 60\n",
        "    print('###################################################################')\n",
        "    print(f'Training CIFAR10 without using DeepSpeed used {no_ds_time:.3f} minutes')\n",
        "    print('###################################################################')\n",
        "    print(f'DeepSpeed accelerated training by {no_ds_time - ds_time:.3f} minutes')        \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_cifar10.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB2k5F8oXkkd",
        "outputId": "b08b645c-6dce-44e0-c9dc-6d32bec741f6"
      },
      "source": [
        "!deepspeed train_cifar10.py --deepspeed_config ds_config.json"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2021-09-15 08:34:17,171] [WARNING] [runner.py:122:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2021-09-15 08:34:17,196] [INFO] [runner.py:360:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 train_cifar10.py --deepspeed_config ds_config.json\n",
            "[2021-09-15 08:34:18,096] [INFO] [launch.py:73:main] 0 NCCL_VERSION 2.7.8\n",
            "[2021-09-15 08:34:18,096] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2021-09-15 08:34:18,097] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2021-09-15 08:34:18,097] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2021-09-15 08:34:18,097] [INFO] [launch.py:102:main] dist_world_size=1\n",
            "[2021-09-15 08:34:18,097] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n",
            "170499072it [00:02, 62596756.56it/s]                   \n",
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "[2021-09-15 08:34:25,400] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.5.2, git-hash=unknown, git-branch=unknown\n",
            "[2021-09-15 08:34:25,402] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
            "[2021-09-15 08:34:27,562] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed groups\n",
            "[2021-09-15 08:34:27,562] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed model parallel group with size 1\n",
            "[2021-09-15 08:34:27,562] [INFO] [logging.py:68:log_dist] [Rank 0] initializing deepspeed expert parallel group with size 1\n",
            "[2021-09-15 08:34:27,563] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0]\n",
            "[2021-09-15 08:34:27,563] [INFO] [logging.py:68:log_dist] [Rank 0] creating expert parallel process group with ranks: [0]\n",
            "[2021-09-15 08:34:27,629] [INFO] [engine.py:198:__init__] DeepSpeed Flops Profiler Enabled: False\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/fused_adam...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/3] /usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.7/dist-packages/torch/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.7/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_37,code=sm_37 --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode=arch=compute_37,code=sm_37 -gencode=arch=compute_37,code=compute_37 -std=c++14 -c /usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "[2/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/includes -isystem /usr/local/lib/python3.7/dist-packages/torch/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.7/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -c /usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o \n",
            "[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 36.388628005981445 seconds\n",
            "[2021-09-15 08:35:04,879] [INFO] [engine.py:820:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer\n",
            "[2021-09-15 08:35:04,882] [INFO] [engine.py:827:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2021-09-15 08:35:04,882] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n",
            "[2021-09-15 08:35:04,883] [INFO] [engine.py:546:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
            "[2021-09-15 08:35:04,883] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fb6ed6b8d10>\n",
            "[2021-09-15 08:35:04,883] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2021-09-15 08:35:04,883] [INFO] [config.py:940:print] DeepSpeedEngine configuration:\n",
            "[2021-09-15 08:35:04,884] [INFO] [config.py:944:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2021-09-15 08:35:04,884] [INFO] [config.py:944:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2021-09-15 08:35:04,885] [INFO] [config.py:944:print]   allreduce_always_fp32 ........ False\n",
            "[2021-09-15 08:35:04,885] [INFO] [config.py:944:print]   amp_enabled .................. False\n",
            "[2021-09-15 08:35:04,885] [INFO] [config.py:944:print]   amp_params ................... False\n",
            "[2021-09-15 08:35:04,885] [INFO] [config.py:944:print]   checkpoint_tag_validation_enabled  True\n",
            "[2021-09-15 08:35:04,885] [INFO] [config.py:944:print]   checkpoint_tag_validation_fail  False\n",
            "[2021-09-15 08:35:04,885] [INFO] [config.py:944:print]   curriculum_enabled ........... False\n",
            "[2021-09-15 08:35:04,885] [INFO] [config.py:944:print]   curriculum_params ............ False\n",
            "[2021-09-15 08:35:04,885] [INFO] [config.py:944:print]   dataloader_drop_last ......... False\n",
            "[2021-09-15 08:35:04,885] [INFO] [config.py:944:print]   disable_allgather ............ False\n",
            "[2021-09-15 08:35:04,886] [INFO] [config.py:944:print]   dump_state ................... False\n",
            "[2021-09-15 08:35:04,886] [INFO] [config.py:944:print]   dynamic_loss_scale_args ...... None\n",
            "[2021-09-15 08:35:04,886] [INFO] [config.py:944:print]   eigenvalue_enabled ........... False\n",
            "[2021-09-15 08:35:04,886] [INFO] [config.py:944:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2021-09-15 08:35:04,886] [INFO] [config.py:944:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2021-09-15 08:35:04,886] [INFO] [config.py:944:print]   eigenvalue_layer_num ......... 0\n",
            "[2021-09-15 08:35:04,886] [INFO] [config.py:944:print]   eigenvalue_max_iter .......... 100\n",
            "[2021-09-15 08:35:04,887] [INFO] [config.py:944:print]   eigenvalue_stability ......... 1e-06\n",
            "[2021-09-15 08:35:04,887] [INFO] [config.py:944:print]   eigenvalue_tol ............... 0.01\n",
            "[2021-09-15 08:35:04,887] [INFO] [config.py:944:print]   eigenvalue_verbose ........... False\n",
            "[2021-09-15 08:35:04,887] [INFO] [config.py:944:print]   elasticity_enabled ........... False\n",
            "[2021-09-15 08:35:04,887] [INFO] [config.py:944:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2021-09-15 08:35:04,887] [INFO] [config.py:944:print]   fp16_enabled ................. False\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   fp16_master_weights_and_gradients  False\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   fp16_mixed_quantize .......... False\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   global_rank .................. 0\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   gradient_accumulation_steps .. 1\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   gradient_clipping ............ 0.0\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   gradient_predivide_factor .... 1.0\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   initial_dynamic_scale ........ 4294967296\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   loss_scale ................... 0\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   memory_breakdown ............. False\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   optimizer_legacy_fusion ...... False\n",
            "[2021-09-15 08:35:04,888] [INFO] [config.py:944:print]   optimizer_name ............... adam\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   pld_enabled .................. False\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   pld_params ................... False\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   prescale_gradients ........... False\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   quantize_change_rate ......... 0.001\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   quantize_groups .............. 1\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   quantize_offset .............. 1000\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   quantize_period .............. 1000\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   quantize_rounding ............ 0\n",
            "[2021-09-15 08:35:04,889] [INFO] [config.py:944:print]   quantize_start_bits .......... 16\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   quantize_target_bits ......... 8\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   quantize_training_enabled .... False\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   quantize_type ................ 0\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   quantize_verbose ............. False\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   scheduler_name ............... WarmupLR\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   sparse_attention ............. None\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   sparse_gradients_enabled ..... False\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   steps_per_print .............. 2000\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   tensorboard_enabled .......... False\n",
            "[2021-09-15 08:35:04,890] [INFO] [config.py:944:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
            "[2021-09-15 08:35:04,891] [INFO] [config.py:944:print]   tensorboard_output_path ...... \n",
            "[2021-09-15 08:35:04,891] [INFO] [config.py:944:print]   train_batch_size ............. 4\n",
            "[2021-09-15 08:35:04,891] [INFO] [config.py:944:print]   train_micro_batch_size_per_gpu  4\n",
            "[2021-09-15 08:35:04,891] [INFO] [config.py:944:print]   use_quantizer_kernel ......... False\n",
            "[2021-09-15 08:35:04,891] [INFO] [config.py:944:print]   wall_clock_breakdown ......... False\n",
            "[2021-09-15 08:35:04,891] [INFO] [config.py:944:print]   world_size ................... 1\n",
            "[2021-09-15 08:35:04,891] [INFO] [config.py:944:print]   zero_allow_untested_optimizer  False\n",
            "[2021-09-15 08:35:04,892] [INFO] [config.py:944:print]   zero_config .................. {\n",
            "    \"stage\": 0, \n",
            "    \"contiguous_gradients\": true, \n",
            "    \"reduce_scatter\": true, \n",
            "    \"reduce_bucket_size\": 5.000000e+08, \n",
            "    \"allgather_partitions\": true, \n",
            "    \"allgather_bucket_size\": 5.000000e+08, \n",
            "    \"overlap_comm\": false, \n",
            "    \"load_from_fp32_weights\": true, \n",
            "    \"elastic_checkpoint\": true, \n",
            "    \"offload_param\": null, \n",
            "    \"offload_optimizer\": null, \n",
            "    \"sub_group_size\": 1.000000e+09, \n",
            "    \"prefetch_bucket_size\": 5.000000e+07, \n",
            "    \"param_persistence_threshold\": 1.000000e+05, \n",
            "    \"max_live_parameters\": 1.000000e+09, \n",
            "    \"max_reuse_distance\": 1.000000e+09, \n",
            "    \"gather_fp16_weights_on_model_save\": false, \n",
            "    \"ignore_unused_parameters\": true, \n",
            "    \"round_robin_gradients\": false, \n",
            "    \"legacy_stage1\": false\n",
            "}\n",
            "[2021-09-15 08:35:04,892] [INFO] [config.py:944:print]   zero_enabled ................. False\n",
            "[2021-09-15 08:35:04,892] [INFO] [config.py:944:print]   zero_optimization_stage ...... 0\n",
            "[2021-09-15 08:35:04,892] [INFO] [config.py:951:print]   json = {\n",
            "    \"train_batch_size\": 4, \n",
            "    \"steps_per_print\": 2.000000e+03, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 0.001, \n",
            "            \"betas\": [0.8, 0.999], \n",
            "            \"eps\": 1e-08, \n",
            "            \"weight_decay\": 3e-07\n",
            "        }\n",
            "    }, \n",
            "    \"scheduler\": {\n",
            "        \"type\": \"WarmupLR\", \n",
            "        \"params\": {\n",
            "            \"warmup_min_lr\": 0, \n",
            "            \"warmup_max_lr\": 0.001, \n",
            "            \"warmup_num_steps\": 1000\n",
            "        }\n",
            "    }, \n",
            "    \"wall_clock_breakdown\": false\n",
            "}\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/utils...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.7/dist-packages/torch/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.7/dist-packages/torch/include/THC -isystem /usr/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -c /usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o \n",
            "[2/2] c++ flatten_unflatten.o -shared -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 15.797650575637817 seconds\n",
            "[2021-09-15 08:37:12,988] [INFO] [logging.py:68:log_dist] [Rank 0] step=2000, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2021-09-15 08:37:13,009] [INFO] [timer.py:160:stop] 0/2000, SamplesPerSec=71.3681517294023\n",
            "[2021-09-15 08:39:05,164] [INFO] [logging.py:68:log_dist] [Rank 0] step=4000, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2021-09-15 08:39:05,182] [INFO] [timer.py:160:stop] 0/4000, SamplesPerSec=71.37421463055067\n",
            "[2021-09-15 08:40:57,380] [INFO] [logging.py:68:log_dist] [Rank 0] step=6000, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2021-09-15 08:40:57,400] [INFO] [timer.py:160:stop] 0/6000, SamplesPerSec=71.36639149574478\n",
            "[2021-09-15 08:42:49,653] [INFO] [logging.py:68:log_dist] [Rank 0] step=8000, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2021-09-15 08:42:49,662] [INFO] [timer.py:160:stop] 0/8000, SamplesPerSec=71.35513446656527\n",
            "[2021-09-15 08:44:42,586] [INFO] [logging.py:68:log_dist] [Rank 0] step=10000, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2021-09-15 08:44:42,605] [INFO] [timer.py:160:stop] 0/10000, SamplesPerSec=71.26305329813162\n",
            "[2021-09-15 08:46:35,669] [INFO] [logging.py:68:log_dist] [Rank 0] step=12000, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n",
            "[2021-09-15 08:46:35,687] [INFO] [timer.py:160:stop] 0/12000, SamplesPerSec=71.18689507805091\n",
            "###################################################################\n",
            "Training CIFAR10 using DeepSpeed used 11.722 minutes\n",
            "Traceback (most recent call last):\n",
            "  File \"train_cifar10.py\", line 243, in <module>\n",
            "    main()    \n",
            "  File \"train_cifar10.py\", line 230, in main\n",
            "    outputs = model(inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"train_cifar10.py\", line 163, in forward\n",
            "    x = self.transformer(x, mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"train_cifar10.py\", line 121, in forward\n",
            "    x = attn(x, mask = mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"train_cifar10.py\", line 52, in forward\n",
            "    return self.fn(x, **kwargs) + x\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"train_cifar10.py\", line 60, in forward\n",
            "    return self.fn(self.norm(x), **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"train_cifar10.py\", line 90, in forward\n",
            "    qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 93, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1692, in linear\n",
            "    output = input.matmul(weight.t())\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 11.17 GiB total capacity; 10.50 GiB already allocated; 44.81 MiB free; 10.70 GiB reserved in total by PyTorch)\n",
            "Killing subprocess 332\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/launcher/launch.py\", line 171, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/launcher/launch.py\", line 161, in main\n",
            "    sigkill_handler(signal.SIGTERM, None)  # not coming back\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deepspeed/launcher/launch.py\", line 139, in sigkill_handler\n",
            "    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'train_cifar10.py', '--local_rank=0', '--deepspeed_config', 'ds_config.json']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdhoeHGgsimM"
      },
      "source": [
        "import os\n",
        "\n",
        "gpu_gtg = False\n",
        "if int(os.environ.get(\"COLAB_GPU\")) > 0:\n",
        "    gpu_gtg = \"COLAB_GPU\" in os.environ\n",
        "\n",
        "tpu_gtg = \"COLAB_TPU_ADDR\" in os.environ\n",
        "\n",
        "if tpu_gtg: # tpu\n",
        "    print(\"TPU\")\n",
        "    #VERSION = \"nightly\"\n",
        "\n",
        "    # https://github.com/pytorch/builder/pull/750\n",
        "    VERSION = \"20210304\" # was 20200607\" \n",
        "\n",
        "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "    !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27ND-qg2tJEU",
        "outputId": "49abac2c-4b4b-4801-f031-09606d4f27de"
      },
      "source": [
        "!pip install --pre pytorch-ignite"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.5.0.dev20210915-py3-none-any.whl (233 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 233 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.5.0.dev20210915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x8df-WuRtBF",
        "outputId": "b666eacc-a43f-4b39-ded1-46c78d566768"
      },
      "source": [
        "# !pip install fairscale\n",
        "!pip install deepspeed"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.5.2.tar.gz (477 kB)\n",
            "\u001b[K     |████████████████████████████████| 477 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed) (4.62.0)\n",
            "Collecting tensorboardX==1.8\n",
            "  Downloading tensorboardX-1.8-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 28.7 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Using cached ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.19.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed) (5.4.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deepspeed) (21.0)\n",
            "Collecting triton\n",
            "  Downloading triton-1.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2 MB 33.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->deepspeed) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deepspeed) (2.4.7)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.5.2-py3-none-any.whl size=479879 sha256=21dc2fa500eb5e1c62c019e733cc66f94db9aa0cc157e96084c29345f0c04161\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/57/72/d7669268042846842d93c36e1447bc7cd8603f77bbbd8ee62b\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: triton, tensorboardX, ninja, deepspeed\n",
            "Successfully installed deepspeed-0.5.2 ninja-1.10.2 tensorboardX-1.8 triton-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYoQTy8JtJBU"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "import ignite\n",
        "import ignite.distributed as idist\n",
        "from ignite.engine import Engine, Events, create_supervised_evaluator, create_supervised_trainer\n",
        "from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\n",
        "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
        "from ignite.utils import setup_logger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va-GVsDLyijz"
      },
      "source": [
        "def training(local_rank, config, **kwargs):\n",
        "    print(\"local rank: \", local_rank)\n",
        "\n",
        "    ###########################################################\n",
        "    # 데이터 준비\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Pad(4),\n",
        "            transforms.RandomCrop(32, fill=128),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),])\n",
        "\n",
        "    if idist.get_local_rank() > 0:\n",
        "        idist.barrier()\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root=config[\"data_path\"], train=True, download=True, transform=train_transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root=config[\"data_path\"], train=False, download=True, transform=test_transform)\n",
        "\n",
        "    if idist.get_local_rank() == 0:\n",
        "        idist.barrier()\n",
        "\n",
        "    trainloader = idist.auto_dataloader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=config[\"num_workers\"], drop_last=True)\n",
        "    testloader = idist.auto_dataloader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=config[\"num_workers\"],)\n",
        "\n",
        "\n",
        "    ###########################################################\n",
        "    # 모델, 옵티마이저, 로스, 트레이너, 이밸류에이터\n",
        "    num_classes = 10\n",
        "    model = models.resnet18(num_classes = num_classes)\n",
        "       \n",
        "    model = idist.auto_model(model)\n",
        "    optimizer = idist.auto_optim(optim.Adam(model.parameters(), lr=0.001))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(idist.device())\n",
        "\n",
        "    trainer = create_supervised_trainer(model, optimizer, criterion, device=idist.device())\n",
        "    trainer.logger = setup_logger(\"hkim-trainer\")\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy':Accuracy(),\n",
        "        'ce':Loss(criterion),\n",
        "    }\n",
        "\n",
        "    val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=idist.device())\n",
        "    val_evaluator.logger = setup_logger(\"hkim-val_evaluator\")\n",
        "\n",
        "    # track a running average of the scalar loss output for each batch.\n",
        "    RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n",
        "\n",
        "    ###########################################################\n",
        "    # 이벤트\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_validation_results(trainer):\n",
        "        state = val_evaluator.run(testloader)\n",
        "        metrics = val_evaluator.state.metrics\n",
        "        accuracy = metrics['accuracy']*100\n",
        "        loss = metrics['ce']\n",
        "        log_metrics(val_evaluator.logger, state.epoch, state.times[\"COMPLETED\"], \"validation evaluator\", state.metrics)\n",
        "\n",
        "    trainer.run(trainloader, max_epochs=config[\"num_epochs\"])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ffcb8ebd69d4477d9a10cf197756a675",
            "dd08a66f822f4e498e216da7501c97fd",
            "e81c90c08fdf4470bebab95064ee7df8",
            "85c8efd45f0d45af8405c052daebc2d5",
            "474fb84acb7047f9a281f56af60b047b",
            "8b6bc5064c61471bbc9577c8a0284baa",
            "8228b0bf58614cafa148059b48d81586",
            "4ec282f8d33540779e44c37bf1e3c6f4",
            "a8f9085d92c24ad5903e36d3dac3cf86",
            "3547eed2097c49abb86cfbddb2b3f587",
            "f15a434ae9ce468787e7654a18125239"
          ]
        },
        "id": "FXJzm8yqtI-k",
        "outputId": "363a65d3-c2d9-42bf-8a87-759a9cfb5ce0"
      },
      "source": [
        "config = {\n",
        "    \"seed\": 543,\n",
        "    \"data_path\" : \"./cifar10\",\n",
        "    \"output_path\" : \"./output-cifar10/\",\n",
        "    \"model\" : \"resnet18\",\n",
        "    \"batch_size\" : 512,\n",
        "    \"momentum\" : 0.9,\n",
        "    \"weight_decay\" : 1e-4,\n",
        "    \"num_workers\" : 2,\n",
        "    \"num_epochs\" : 24,\n",
        "    \"learning_rate\" : 0.4,\n",
        "    \"num_warmup_epochs\" : 4,\n",
        "    \"validate_every\" : 3, \n",
        "    \"checkpoint_every\" : 1000,\n",
        "    \"backend\" : None, \n",
        "    \"resume_from\" : None, \n",
        "    \"log_every_iters\" : 15,\n",
        "    \"nproc_per_node\" : None, \n",
        "    \"stop_iteration\" : None, \n",
        "    \"with_amp\" : False,\n",
        "    \"log_interval\" : 10,\n",
        "    \"verbose_set\" : False,\n",
        "    \"verbose_set2\" : False,\n",
        "    \"verbose_loader\" : False\n",
        "\n",
        "}\n",
        "\n",
        "if not (tpu_gtg or gpu_gtg): # cpu\n",
        "    config[\"backend\"] = 'gloo'\n",
        "    config[\"nproc_per_node\"] = 8\n",
        "elif gpu_gtg: # gpu\n",
        "    config[\"backend\"] = 'nccl'\n",
        "    config[\"nproc_per_node\"] = 1\n",
        "elif tpu_gtg: # tpu\n",
        "    config[\"backend\"] = 'xla-tpu'\n",
        "    config[\"nproc_per_node\"] = 8\n",
        "else: # error\n",
        "    raise RuntimeError(\"Unknown environment: tpu_gtg {}, gpu_gtg {}\".format(tpu_gtg, gpu_gtg))\n",
        "\n",
        "if config[\"backend\"] == \"xla-tpu\" and config[\"with_amp\"]:\n",
        "    raise RuntimeError(\"The value of with_amp should be False if backend is xla\")\n",
        "\n",
        "\n",
        "dist_configs = {'nproc_per_node': config[\"nproc_per_node\"], \"start_method\": \"fork\"}  \n",
        "\n",
        "def log_metrics(logger, epoch, elapsed, tag, metrics):\n",
        "    metrics_output = \"\\n\".join([f\"\\t{k}: {v}\" for k, v in metrics.items()])\n",
        "    logger.info(f\"\\nEpoch {epoch} - Evaluation time (seconds): {elapsed:.2f} - {tag} metrics:\\n {metrics_output}\")\n",
        "\n",
        "with idist.Parallel(backend=config[\"backend\"], **dist_configs) as parallel:\n",
        "    parallel.run(training, config, a=1, b=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-09-13 07:43:17,782 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'xla-tpu'\n",
            "2021-09-13 07:43:17,784 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: \n",
            "\tnproc_per_node: 8\n",
            "\tnnodes: 1\n",
            "\tnode_rank: 0\n",
            "\tstart_method: fork\n",
            "2021-09-13 07:43:17,786 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x7fa2a1e58cb0>' in 8 processes\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "local rank:  7\n",
            "local rank:  2\n",
            "local rank:  5\n",
            "local rank:  1\n",
            "local rank:  3\n",
            "local rank:  6\n",
            "local rank:  4\n",
            "local rank:  0\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffcb8ebd69d4477d9a10cf197756a675",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-09-13 07:44:48,697 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': \n",
            "\t{'batch_size': 64, 'num_workers': 2, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x7fa2b316a450>, 'pin_memory': False}\n",
            "2021-09-13 07:44:48,719 ignite.distributed.auto.auto_dataloader INFO: DataLoader is wrapped by `MpDeviceLoader` on XLA\n",
            "2021-09-13 07:44:48,740 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': \n",
            "\t{'batch_size': 64, 'num_workers': 2, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x7fa29afa2050>, 'pin_memory': False}\n",
            "2021-09-13 07:44:48,753 ignite.distributed.auto.auto_dataloader INFO: DataLoader is wrapped by `MpDeviceLoader` on XLA\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-09-13 07:44:50,868 hkim-trainer INFO: Engine run starting with max_epochs=24.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-13 07:45:45,149 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:45:50,900 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
            "2021-09-13 07:45:50,918 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:06\n",
            "2021-09-13 07:45:50,926 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 5.76 - validation evaluator metrics:\n",
            " \taccuracy: 0.5083\n",
            "\tce: 1.3657859375\n",
            "2021-09-13 07:45:50,930 hkim-trainer INFO: Epoch[1] Complete. Time taken: 00:00:60\n",
            "2021-09-13 07:46:23,184 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:46:26,740 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:46:26,750 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:46:26,759 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.54 - validation evaluator metrics:\n",
            " \taccuracy: 0.5722\n",
            "\tce: 1.19976494140625\n",
            "2021-09-13 07:46:26,771 hkim-trainer INFO: Epoch[2] Complete. Time taken: 00:00:36\n",
            "2021-09-13 07:46:58,130 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:47:01,713 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:47:01,734 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:47:01,746 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.59 - validation evaluator metrics:\n",
            " \taccuracy: 0.6515\n",
            "\tce: 1.002620703125\n",
            "2021-09-13 07:47:01,765 hkim-trainer INFO: Epoch[3] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:47:33,016 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:47:36,575 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:47:36,593 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:47:36,607 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.56 - validation evaluator metrics:\n",
            " \taccuracy: 0.6691\n",
            "\tce: 0.9666755859375\n",
            "2021-09-13 07:47:36,633 hkim-trainer INFO: Epoch[4] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:48:07,789 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:48:11,357 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:48:11,372 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:48:11,388 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.57 - validation evaluator metrics:\n",
            " \taccuracy: 0.7045\n",
            "\tce: 0.85864794921875\n",
            "2021-09-13 07:48:11,399 hkim-trainer INFO: Epoch[5] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:48:42,872 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:48:46,454 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:48:46,468 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:48:46,484 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.59 - validation evaluator metrics:\n",
            " \taccuracy: 0.7119\n",
            "\tce: 0.83871806640625\n",
            "2021-09-13 07:48:46,508 hkim-trainer INFO: Epoch[6] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:49:18,173 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:49:21,721 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:49:21,737 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:49:21,767 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.54 - validation evaluator metrics:\n",
            " \taccuracy: 0.7169\n",
            "\tce: 0.8235662109375\n",
            "2021-09-13 07:49:21,789 hkim-trainer INFO: Epoch[7] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:49:53,025 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:49:56,617 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:49:56,634 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:49:56,648 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.59 - validation evaluator metrics:\n",
            " \taccuracy: 0.7206\n",
            "\tce: 0.82320224609375\n",
            "2021-09-13 07:49:56,665 hkim-trainer INFO: Epoch[8] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:50:28,430 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:50:31,960 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:50:31,977 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:50:31,996 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.53 - validation evaluator metrics:\n",
            " \taccuracy: 0.7455\n",
            "\tce: 0.74374326171875\n",
            "2021-09-13 07:50:32,020 hkim-trainer INFO: Epoch[9] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:51:03,536 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:51:07,094 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:51:07,115 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:51:07,138 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.56 - validation evaluator metrics:\n",
            " \taccuracy: 0.7411\n",
            "\tce: 0.75353056640625\n",
            "2021-09-13 07:51:07,161 hkim-trainer INFO: Epoch[10] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:51:38,599 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:51:42,234 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:04\n",
            "2021-09-13 07:51:42,254 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:51:42,270 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.64 - validation evaluator metrics:\n",
            " \taccuracy: 0.7564\n",
            "\tce: 0.7184125\n",
            "2021-09-13 07:51:42,291 hkim-trainer INFO: Epoch[11] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:52:13,703 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:52:17,245 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:52:17,267 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:52:17,282 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.56 - validation evaluator metrics:\n",
            " \taccuracy: 0.7616\n",
            "\tce: 0.6881111328125\n",
            "2021-09-13 07:52:17,304 hkim-trainer INFO: Epoch[12] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:52:48,712 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:52:52,225 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:52:52,242 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:52:52,264 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.52 - validation evaluator metrics:\n",
            " \taccuracy: 0.7654\n",
            "\tce: 0.699411962890625\n",
            "2021-09-13 07:52:52,277 hkim-trainer INFO: Epoch[13] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:53:23,473 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:53:27,002 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:53:27,007 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:53:27,013 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.51 - validation evaluator metrics:\n",
            " \taccuracy: 0.7669\n",
            "\tce: 0.70954326171875\n",
            "2021-09-13 07:53:27,023 hkim-trainer INFO: Epoch[14] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:53:58,275 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:54:01,823 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:54:01,848 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:54:01,868 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.56 - validation evaluator metrics:\n",
            " \taccuracy: 0.7611\n",
            "\tce: 0.709891162109375\n",
            "2021-09-13 07:54:01,895 hkim-trainer INFO: Epoch[15] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:54:33,219 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:54:36,872 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:04\n",
            "2021-09-13 07:54:36,895 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:54:36,923 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.67 - validation evaluator metrics:\n",
            " \taccuracy: 0.7615\n",
            "\tce: 0.728841552734375\n",
            "2021-09-13 07:54:36,964 hkim-trainer INFO: Epoch[16] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:55:07,877 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:55:11,420 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:55:11,436 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:55:11,455 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.54 - validation evaluator metrics:\n",
            " \taccuracy: 0.77\n",
            "\tce: 0.6952634765625\n",
            "2021-09-13 07:55:11,467 hkim-trainer INFO: Epoch[17] Complete. Time taken: 00:00:34\n",
            "2021-09-13 07:55:42,406 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:55:45,999 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:55:46,014 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:55:46,037 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.61 - validation evaluator metrics:\n",
            " \taccuracy: 0.7725\n",
            "\tce: 0.685089990234375\n",
            "2021-09-13 07:55:46,057 hkim-trainer INFO: Epoch[18] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:56:17,155 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:56:20,766 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:56:20,774 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:56:20,785 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.59 - validation evaluator metrics:\n",
            " \taccuracy: 0.7778\n",
            "\tce: 0.66795830078125\n",
            "2021-09-13 07:56:20,794 hkim-trainer INFO: Epoch[19] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:56:52,105 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:56:55,631 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:56:55,655 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:56:55,670 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.53 - validation evaluator metrics:\n",
            " \taccuracy: 0.791\n",
            "\tce: 0.63057861328125\n",
            "2021-09-13 07:56:55,687 hkim-trainer INFO: Epoch[20] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:57:26,883 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:57:30,494 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:04\n",
            "2021-09-13 07:57:30,508 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:57:30,516 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.61 - validation evaluator metrics:\n",
            " \taccuracy: 0.7788\n",
            "\tce: 0.68194951171875\n",
            "2021-09-13 07:57:30,532 hkim-trainer INFO: Epoch[21] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:58:01,960 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:58:05,571 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:04\n",
            "2021-09-13 07:58:05,580 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:58:05,592 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.61 - validation evaluator metrics:\n",
            " \taccuracy: 0.7892\n",
            "\tce: 0.6449546875\n",
            "2021-09-13 07:58:05,603 hkim-trainer INFO: Epoch[22] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:58:37,039 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:58:40,568 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:58:40,590 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:58:40,607 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.53 - validation evaluator metrics:\n",
            " \taccuracy: 0.7823\n",
            "\tce: 0.665587109375\n",
            "2021-09-13 07:58:40,625 hkim-trainer INFO: Epoch[23] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:59:12,041 hkim-val_evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2021-09-13 07:59:15,555 hkim-val_evaluator INFO: Epoch[1] Complete. Time taken: 00:00:03\n",
            "2021-09-13 07:59:15,613 hkim-val_evaluator INFO: Engine run complete. Time taken: 00:00:04\n",
            "2021-09-13 07:59:15,628 hkim-val_evaluator INFO: \n",
            "Epoch 1 - Evaluation time (seconds): 3.56 - validation evaluator metrics:\n",
            " \taccuracy: 0.7856\n",
            "\tce: 0.67493076171875\n",
            "2021-09-13 07:59:15,635 hkim-trainer INFO: Epoch[24] Complete. Time taken: 00:00:35\n",
            "2021-09-13 07:59:15,643 hkim-trainer INFO: Engine run complete. Time taken: 00:14:25\n",
            "2021-09-13 07:59:15,717 ignite.distributed.launcher.Parallel INFO: End of run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQL39wXmXx9k"
      },
      "source": [
        "## License\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXio6q3iX5Ig"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "Note: This is not an official [LG AI Research](https://www.lgresearch.ai/) product but sample code provided for an educational purpose\n",
        "\n",
        "<br/>\n",
        "author: John H. Kim\n",
        "<br/>  \n",
        "email: john.kim@lgresearch.ai / secutron@naver.com  \n",
        "\n",
        "\n",
        "---"
      ]
    }
  ]
}