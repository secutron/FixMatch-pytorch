{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FixMatch-pytorch-on-TPUs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/FixMatch-pytorch/blob/master/FixMatch_pytorch_on_TPUs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw62m-MtZmUw"
      },
      "source": [
        "# FixMatch with Pytorch on TPUs - experimental\n",
        "\n",
        "Code: https://github.com/vfdev-5/FixMatch-pytorch/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djEc5_w9Clbu"
      },
      "source": [
        "### Install requirements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gifW7MX3eSaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "d25b6ca4-a0fb-4465-c98f-63dfc2b87c16"
      },
      "source": [
        "'''\n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        "\n",
        "\n",
        "try:\n",
        "  import torch_xla\n",
        "  import ignite\n",
        "except ImportError:\n",
        "  VERSION = \"20210304\"    \n",
        "  # VERSION = \"nightly\"\n",
        "  # VERSION = \"20200607\"\n",
        "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "  !python pytorch-xla-env-setup.py --version $VERSION\n",
        "  !pip install --upgrade git+https://github.com/pytorch/ignite\n",
        "  !pip install --upgrade --pre hydra-core\n",
        "  !pip install wandb\n",
        "  !pip uninstall -y pillow && CC=\"cc -mavx2\" pip install --no-cache-dir --force-reinstall pillow-simd\n",
        "'''\n",
        "\n",
        "  !pip install ignite\n",
        "  !pip install hydra-core"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d3522aa51a03>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    get_ipython().system('pip install ignite')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oicoHubCt_r"
      },
      "source": [
        "### Download dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxMvVxoalCUi"
      },
      "source": [
        "# Download dataset:\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "CIFAR10(\"./cifar10\", train=True, download=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS-0uom3CxF0"
      },
      "source": [
        "### Get the code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQU8AkGUUnrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5bfaff-365e-4d85-9fa3-035573a06dc7"
      },
      "source": [
        "!git clone https://github.com/secutron/FixMatch-pytorch/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FixMatch-pytorch'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (277/277), done.\u001b[K\n",
            "remote: Compressing objects: 100% (177/177), done.\u001b[K\n",
            "remote: Total 277 (delta 156), reused 164 (delta 76), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (277/277), 108.67 KiB | 7.24 MiB/s, done.\n",
            "Resolving deltas: 100% (156/156), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-45vgIcDCgj"
      },
      "source": [
        "#### Optionally, login to `W&B`\n",
        "\n",
        "To skip logging to `W&B`, please set `online_exp_tracking.wandb=false` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOTdc6wXU94W"
      },
      "source": [
        "# !wandb login <token>"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGu44tDFDkjQ"
      },
      "source": [
        "### Let's train ResNet18 model in a faster mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poJkPrRCPJDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad78d83e-9feb-492f-9a17-f334ad3032c2"
      },
      "source": [
        "\n",
        "'''\n",
        "!cd FixMatch-pytorch && export PYTHONPATH=$PWD:$PYTHONPATH && \\\n",
        "  python main_fixmatch.py distributed.backend=xla-tpu distributed.nproc_per_node=8 online_exp_tracking.wandb=true solver.num_epochs=1 \\\n",
        "    ssl.confidence_threshold=0.7 ema_decay=0.9 ssl.cta_update_every=15 solver.optimizer.params.lr=0.1\n",
        "'''\n",
        "\n",
        "!cd FixMatch-pytorch && export PYTHONPATH=$PWD:$PYTHONPATH && \\\n",
        "  python main_fixmatch.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/hydra/core/default_element.py:127: UserWarning: In 'ssl/cta_pseudo': Usage of deprecated keyword in package header '# @package _group_'.\n",
            "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
            "  See {url} for more information\"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/core/default_element.py:127: UserWarning: In 'solver/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
            "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
            "  See {url} for more information\"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/core/default_element.py:127: UserWarning: In 'dataflow/cifar10': Usage of deprecated keyword in package header '# @package _group_'.\n",
            "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
            "  See {url} for more information\"\"\"\n",
            "2021-08-04 08:23:54,643 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'xla-tpu'\n",
            "2021-08-04 08:23:54,643 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: \n",
            "\tnproc_per_node: 8\n",
            "\tnnodes: 1\n",
            "\tnode_rank: 0\n",
            "2021-08-04 08:23:54,643 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x7f6bdc2fb7a0>' in 8 processes\n",
            "2021-08-04 08:24:21,168 FixMatch Training INFO: {'dataflow': {'name': 'cifar10', 'data_path': '/content/cifar10', 'batch_size': 64, 'num_workers': 12}, 'solver': {'num_epochs': 1, 'epoch_length': 128, 'checkpoint_every': 500, 'validate_every': 1, 'resume_from': None, 'optimizer': {'cls': 'torch.optim.SGD', 'params': {'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': False}, 'param_groups': {'lr': 0.03, 'momentum': 0.9, 'weight_decay': 0.0001, 'nesterov': False}}, 'supervised_criterion': {'cls': 'torch.nn.CrossEntropyLoss'}, 'lr_scheduler': {'cls': 'torch.optim.lr_scheduler.CosineAnnealingLR', 'params': {'eta_min': 0.0, 'T_max': None}, 'param_groups': {'eta_min': 0.0, 'T_max': None}}, 'unsupervised_criterion': {'cls': 'torch.nn.CrossEntropyLoss', 'params': {'reduction': 'none'}, 'param_groups': {'reduction': 'none'}}}, 'ssl': {'num_train_samples_per_class': 25, 'confidence_threshold': 0.7, 'lambda_u': 1.0, 'mu_ratio': 7, 'cta_update_every': 15}, 'name': 'fixmatch', 'seed': 543, 'debug': False, 'model': 'resnet18', 'num_classes': 10, 'ema_decay': 0.9, 'distributed': {'backend': 'xla-tpu', 'nproc_per_node': 8}, 'online_exp_tracking': {'wandb': True}}\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "2021-08-04 08:24:37,733 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset '<dataflow.Transforme': \n",
            "\t{'batch_size': 8, 'num_workers': 2, 'pin_memory': False, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x7f6bd1dc3110>}\n",
            "2021-08-04 08:24:37,745 ignite.distributed.auto.auto_dataloader INFO: DataLoader is wrapped by `MpDeviceLoader` on XLA\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Exception in device=TPU:5: If with_unsup=True, cta should be defined, but given None\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/distributed/comp_models/xla.py\", line 107, in _dist_worker_task_fn\n",
            "    fn(local_rank, *args, **kwargs_dict)\n",
            "  File \"main_fixmatch.py\", line 60, in training\n",
            "    ) = utils.get_dataflow(cfg, cta=cta, with_unsup=True)\n",
            "  File \"/content/FixMatch-pytorch/utils.py\", line 67, in get_dataflow\n",
            "    \"If with_unsup=True, cta should be defined, but given None\"\n",
            "ValueError: If with_unsup=True, cta should be defined, but given None\n",
            "Exception in device=TPU:2: If with_unsup=True, cta should be defined, but given None\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/distributed/comp_models/xla.py\", line 107, in _dist_worker_task_fn\n",
            "    fn(local_rank, *args, **kwargs_dict)\n",
            "  File \"main_fixmatch.py\", line 60, in training\n",
            "    ) = utils.get_dataflow(cfg, cta=cta, with_unsup=True)\n",
            "  File \"/content/FixMatch-pytorch/utils.py\", line 67, in get_dataflow\n",
            "    \"If with_unsup=True, cta should be defined, but given None\"\n",
            "ValueError: If with_unsup=True, cta should be defined, but given None\n",
            "Exception in device=TPU:6: If with_unsup=True, cta should be defined, but given None\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/distributed/comp_models/xla.py\", line 107, in _dist_worker_task_fn\n",
            "    fn(local_rank, *args, **kwargs_dict)\n",
            "  File \"main_fixmatch.py\", line 60, in training\n",
            "    ) = utils.get_dataflow(cfg, cta=cta, with_unsup=True)\n",
            "  File \"/content/FixMatch-pytorch/utils.py\", line 67, in get_dataflow\n",
            "    \"If with_unsup=True, cta should be defined, but given None\"\n",
            "ValueError: If with_unsup=True, cta should be defined, but given None\n",
            "Error executing job with overrides: ['distributed.backend=xla-tpu', 'distributed.nproc_per_node=8', 'online_exp_tracking.wandb=true', 'solver.num_epochs=1', 'ssl.confidence_threshold=0.7', 'ema_decay=0.9', 'ssl.cta_update_every=15', 'solver.optimizer.params.lr=0.1']\n",
            "Traceback (most recent call last):\n",
            "  File \"main_fixmatch.py\", line 211, in main\n",
            "    parallel.run(training, cfg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/distributed/launcher.py\", line 307, in run\n",
            "    idist.spawn(self.backend, func, args=args, kwargs_dict=kwargs, **self._spawn_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/distributed/utils.py\", line 324, in spawn\n",
            "    fn, args=args, kwargs_dict=kwargs_dict, nproc_per_node=nproc_per_node, backend=backend, **kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/distributed/comp_models/xla.py\", line 128, in spawn\n",
            "    **kwargs,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 394, in spawn\n",
            "    start_method=start_method)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 188, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 144, in join\n",
            "    exit_code=exitcode\n",
            "torch.multiprocessing.spawn.ProcessExitedException: process 5 terminated with exit code 17\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm9LrTRbPI2L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msMIIkIWDddp"
      },
      "source": [
        "### Let's train WRN-28-2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viaP4TVVdGaV"
      },
      "source": [
        "!cd FixMatch-pytorch && export PYTHONPATH=$PWD:$PYTHONPATH && \\\n",
        "  python -u main_fixmatch.py model=WRN-28-2 distributed.backend=xla-tpu distributed.nproc_per_node=8 online_exp_tracking.wandb=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MK5SvZ7DkV4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}